{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Pokémon Name Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project demonstrates how to generate new Pokémon names using Keras and Recurrent Neural Networks (RNNs) with Long Short-Term Memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and perform preprocessing\n",
    "\n",
    "First, we load all Pokémon names from a text file. Each row contains one Pokémon name. We perform some initial preprocessing by removing names from the dataset that include unwanted characters. This will improve the quality of generated names from the neural network.\n",
    "\n",
    "Here, we also set up `char_to_index` and `index_to_char` dictionaries to help us translate between index value and character value. This will come in handy when we encode the dataset into a format that the neural network can operate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    Load data from file.\n",
    "    \n",
    "    :param file_name: The name of the file to load data from.\n",
    "    :return: An array of sequences that represent the file's contents, and \n",
    "    \"\"\"\n",
    "    with open(file_name) as f:\n",
    "        names = f.readlines()\n",
    "\n",
    "    chars = sorted(list(set(\"\".join(name.lower() for name in names))))\n",
    "    data = [name.rstrip().lower() for name in names]\n",
    "\n",
    "    return data, chars\n",
    "\n",
    "def is_invalid(sequence, invalid_chars):\n",
    "    \"\"\"\n",
    "    Filter out words that contain invalid characters.\n",
    "    \n",
    "    :param sequence: The word to analyse.\n",
    "    :param invalid_chars: An array of invalid characters.\n",
    "    :return: True if the sequence contains an invalid character, else return False.\n",
    "    \"\"\"\n",
    "    for char in sequence:\n",
    "        if char in invalid_chars:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data, chars = load_data(\"pokemon.txt\")\n",
    "\n",
    "# Clean data\n",
    "invalid_chars=[' ', \"'\", '-', '.', '2', '♀', '♂', 'é']\n",
    "name_data = [data for data in name_data if not is_invalid(data, invalid_chars)]\n",
    "chars = [char for char in chars if char not in invalid_chars]\n",
    "\n",
    "# Get the longest and shortest names in dataset\n",
    "max_sequence_length = len(max(name_data, key=len))\n",
    "min_sequence_length = len(min(name_data, key=len))\n",
    "\n",
    "# Set up dictionaries to convert between character indexes and vice versa, e.g. 'a' => 1, 'b' => 2. \n",
    "char_to_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 710\n",
      "Max sequence length: 11\n",
      "Min sequence length: 3\n",
      "Total characters: 27\n",
      "\n",
      "Data:\n",
      "1. bulbasaur\n",
      "2. ivysaur\n",
      "3. venusaur\n",
      "4. charmander\n",
      "5. charmeleon\n",
      "...\n",
      "\n",
      "Characters:\n",
      "['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(\"Corpus length: {}\".format(len(name_data)))\n",
    "print(\"Max sequence length: {}\".format(max_sequence_length))\n",
    "print(\"Min sequence length: {}\".format(min_sequence_length))\n",
    "print(\"Total characters: {}\\n\".format(len(chars)))\n",
    "\n",
    "print(\"Data:\")\n",
    "for i in range(5):\n",
    "    print(\"{}. {}\".format((i + 1), name_data[i]))\n",
    "print(\"...\\n\")\n",
    "\n",
    "print(\"Characters:\\n{}\".format(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate training data with sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an array of sequences that are subsets of Pokémon names. We also generate an array of corresponding next characters so that the neural network can learn. We use the sequences and their next characters to train the neural network, which predict the next acharacter based on a given sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(names, sequence_length=4, step=1):\n",
    "    \"\"\"\n",
    "    Generate sequences of characters to use for training.\n",
    "\n",
    "    :param names: Array of names to create sequences from.\n",
    "    :param sequence_length: The length of each sequence generated.\n",
    "    :param step:\n",
    "    :return: An array of generated sequences and an array of corresponding expected next characters.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    name_lengths = []\n",
    "    next_chars = []\n",
    "    \n",
    "    for name in names:\n",
    "        curr_name_length = len(name)\n",
    "        if curr_name_length <= sequence_length:\n",
    "            sequences.append(name[i:i + sequence_length])\n",
    "            next_chars.append(chars[1])\n",
    "            name_lengths.append(len(name))\n",
    "        else:\n",
    "            for i in range(0, curr_name_length - sequence_length + 1, step):\n",
    "                sequences.append(name[i : i + sequence_length])\n",
    "                if (sequence_length + i) < curr_name_length:\n",
    "                    next_chars.append(name[sequence_length + i])\n",
    "                else:\n",
    "                    next_chars.append(chars[1])\n",
    "                name_lengths.append(i + sequence_length)\n",
    "\n",
    "    \n",
    "    print(\"Total sequences generated: {}\".format(len(sequences)))\n",
    "    print(\"Length of sequence: {}\".format(sequence_length))\n",
    "\n",
    "    return sequences, name_lengths, next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences generated: 3126\n",
      "Length of sequence: 4\n",
      "\n",
      "Sample sequences:\n",
      " x: ['bulb'], y: ['a']\n",
      " x: ['ulba'], y: ['s']\n",
      " x: ['lbas'], y: ['a']\n",
      " x: ['basa'], y: ['u']\n",
      " x: ['asau'], y: ['r']\n",
      " x: ['saur'], y: ['a']\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 4\n",
    "sequences, name_lengths, next_chars = generate_sequences(name_data, sequence_length)\n",
    "\n",
    "print(\"\\nSample sequences:\")\n",
    "for i in range(len(name_data[0]) - sequence_length + 1):\n",
    "    print(\" x: ['{}'], y: ['{}']\".format(sequences[i], next_chars[i]))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot encoding the sequences\n",
    "\n",
    "\n",
    "One-hot encoding involves converting each sequence into an array of `0`s where a `1` represents the active letter. For example, the string `abc` becomes `[[1, 0, 0]` `[0, 1, 0]` `[0, 0, 1]]`.\n",
    "\n",
    "We can achieve this using the `char_to_index` dictionary created earlier. This format makes it easy for the neural network model to learn on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(sequences, chars, next_chars):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param sequences:\n",
    "    :param next_chars:\n",
    "    :param chars:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    total_chars = len(chars)\n",
    "    total_next_chars = len(next_chars)\n",
    "    total_sequences = len(sequences)\n",
    "    \n",
    "    x = np.zeros(shape=(total_sequences, max_sequence_length, total_chars), dtype=\"float32\")\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j, char in enumerate(sequence):\n",
    "            x[i, j, char_to_index[char]] = 1\n",
    "                 \n",
    "    y = np.zeros(shape=(total_next_chars, total_chars), dtype=\"float32\")\n",
    "    for i, char in enumerate(next_chars):\n",
    "        y[i, char_to_index[next_chars[i]]] = 1\n",
    "    \n",
    "    print('x.shape: {}'.format(x.shape))\n",
    "    print('y.shape: {}'.format(x.shape))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (3126, 11, 27)\n",
      "y.shape: (3126, 11, 27)\n"
     ]
    }
   ],
   "source": [
    "x, y = one_hot_encoding(sequences, chars, next_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build RNN model with single LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(max_sequence_length, len(chars))),\n",
    "            layers.LSTM(64),\n",
    "            layers.Dense(units=len(chars), activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    \"\"\"\n",
    "    Helper function to sample a character index from an array of probabilities.\n",
    "    \n",
    "    :param preds:\n",
    "    :param temperature:\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(model, sequences, sequence_lengths, chars, temperature=0.3):\n",
    "    \"\"\"\n",
    "    Generate a name using the RNN.\n",
    "    \n",
    "    :param model: The model to predict on.\n",
    "    :param sequences: An array of sequences to train the network on.\n",
    "    :param sequence_lengths: An array of integers that represent the length of each sequence.\n",
    "    :param chars: An array of all characters in the dataset.\n",
    "    :param temperature: A 0-1 value of how confident the RNN model should be. A higher number causes more randomness.\n",
    "    :return: A generated name as a string.\n",
    "    \"\"\"\n",
    "    # Randomly generate a sequence and length\n",
    "    sequence = sequences[np.random.randint(0, (len(sequences) - 1))]\n",
    "    sequence_length = sequence_lengths[np.random.randint(0, (len(sequence_lengths) - 1))]\n",
    "    sequence_length = len(sequence)\n",
    "    result = \"\"\n",
    "    \n",
    "    # Initialise vector and populate with seeded sequence\n",
    "    sequence_input = np.zeros(shape=(1, max_sequence_length, len(chars)))\n",
    "    for i, char in enumerate(sequence):\n",
    "        sequence_input[0, i, char_to_index[char]] = 1\n",
    "\n",
    "    # Predict next character\n",
    "    prediction = model.predict(sequence_input)[0]\n",
    "    next_char_index = sample(prediction, temperature)\n",
    "    \n",
    "    while next_char_index < (len(chars) - 1) and len(result) < sequence_length:\n",
    "        result += chars[next_char_index]\n",
    "        \n",
    "        sequence_input = np.zeros(shape=(1, max_sequence_length, len(chars)))\n",
    "        for i, char in enumerate(result[(-sequence_length):]):\n",
    "            sequence_input[0, i, char_to_index[char]] = 1\n",
    "        \n",
    "        prediction = model.predict(x=[sequence_input])[0]\n",
    "        next_char_index = sample(prediction, temperature)\n",
    "\n",
    "    print(result.capitalize())\n",
    "    return result.capitalize()\n",
    "\n",
    "def generate_names(model, sequences, sequence_lengths, amount=5):\n",
    "    \"\"\"\n",
    "    Generate multiple names.\n",
    "    \n",
    "    :param model: The model to predict new names on.\n",
    "    :param sequences: An array of sequences to train the network on.\n",
    "    :param sequence_lengths: An array of integers that represent the length of each sequence.\n",
    "    :param amount: An integer value of how many names to generate.\n",
    "    :return: Return an array of generated names.\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    for i in range(amount):\n",
    "        name = generate_name(model, sequences, sequence_lengths, chars)\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=180, batch_size=128, verbose=0):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param epochs:\n",
    "    :param print_line:\n",
    "    :param batch_size:\n",
    "    \"\"\"\n",
    "    names, chars = load_data(\"pokemon.txt\")\n",
    "    \n",
    "    names = [name for name in names if not is_invalid(name, invalid_chars)]\n",
    "    chars = [char for char in chars if char not in invalid_chars]\n",
    "    \n",
    "    pokemon_sequences, name_lengths, pokemon_next_chars = generate_sequences(names)\n",
    "    x, y = one_hot_encoding(pokemon_sequences, chars, pokemon_next_chars)\n",
    "    model = generate_model()\n",
    "    \n",
    "    print(\"Generating names...\")\n",
    "    for i in range(epochs):\n",
    "        history = model.fit(x, y, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "        generated = generate_name(model, pokemon_sequences, name_lengths, chars)\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 3126\n",
      "Length of sequences: 4\n",
      "x.shape: (3126, 11, 27)\n",
      "y.shape: (3126, 11, 27)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64)                23552     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 27)                1755      \n",
      "=================================================================\n",
      "Total params: 25,307\n",
      "Trainable params: 25,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Generating names...\n",
      "Kawatte\n",
      "Oaaaart\n",
      "Buatg\n",
      "Easaa\n",
      "Roisaan\n",
      "Sina\n",
      "Peaaa\n",
      "Anart\n",
      "Yacbelum\n",
      "Easas\n",
      "Anartwos\n",
      "Aat\n",
      "Kadoona\n",
      "Laaffya\n",
      "Anara\n",
      "Rawaca\n",
      "Nealyar\n",
      "Aat\n",
      "Iaaaat\n",
      "Odoadaa\n"
     ]
    }
   ],
   "source": [
    "pokemon_names = train_model(epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
